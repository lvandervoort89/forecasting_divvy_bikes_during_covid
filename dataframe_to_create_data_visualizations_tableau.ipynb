{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T02:15:52.401279Z",
     "start_time": "2020-09-13T02:15:52.102147Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T02:20:51.461908Z",
     "start_time": "2020-09-13T02:20:47.210716Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load in data \n",
    "all_data_2020 = pd.read_csv('all_data_2020.csv')\n",
    "all_data_2019 = pd.read_csv('all_data_2019.csv')\n",
    "divvy_bike_stations = pd.read_csv('../Data/Divvy_Bicycle_Stations.csv')\n",
    "chicago_zip_pop_data = pd.read_csv('../Data/Chicago_Population_Counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T02:23:08.286558Z",
     "start_time": "2020-09-13T02:23:07.593874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert start_day_of_year to datetime object\n",
    "all_data_2020.start_day_of_year = pd.to_datetime(all_data_2020.start_day_of_year)\n",
    "all_data_2019.start_day_of_year = pd.to_datetime(all_data_2019.start_day_of_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T02:16:28.185488Z",
     "start_time": "2020-09-13T02:16:28.182573Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_to_csv(data, file_name):\n",
    "    '''\n",
    "    A helper function that saves a dataframe to csv.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : A pandas dataframe\n",
    "    file_name : Name for storing the csv file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A csv named file_name\n",
    "    '''\n",
    "\n",
    "    data.to_csv(f'data/{file_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T02:16:43.092418Z",
     "start_time": "2020-09-13T02:16:43.081959Z"
    }
   },
   "outputs": [],
   "source": [
    "def determine_covid(date):\n",
    "    '''\n",
    "    A helper fucntion that takes in a date and returns a value of 0 or 1 if the\n",
    "    date is during Covid  (March 17-August 31, 2020).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    date : The date of a Divvy bike ride.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A 0 if the date did not take place during Covid and a 1 if the ride took place during\n",
    "    Covid.\n",
    "    '''\n",
    "    if date >= datetime.date(year=2020, month=3, day=17):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def phase_one(date):\n",
    "    '''\n",
    "    A helper fucntion that takes in a date and returns a value of 0 or 1 if the\n",
    "    date is during Chicago's Phase 1 Covid response (March 17-April 30, 2020).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    date : The date of a Divvy bike ride.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A 0 if the date did not take place during Phase 1 and a 1 if the ride took place during\n",
    "    Phase 1.\n",
    "    '''\n",
    "    if (date >= datetime.date(year=2020, month=3, day=17)) and (date <= datetime.date(year=2020, month=4, day=30)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def phase_two(date):\n",
    "    '''\n",
    "    A helper fucntion that takes in a date and returns a value of 0 or 1 if the\n",
    "    date is during Chicago's Phase 2 Covid response (May 1-June 2, 2020).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    date : The date of a Divvy bike ride.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A 0 if the date did not take place during Phase 2 and a 1 if the ride took place during\n",
    "    Phase 2.\n",
    "    '''\n",
    "    if (date >= datetime.date(year=2020, month=5, day=1)) and (date <= datetime.date(year=2020, month=6, day=2)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def phase_three(date):\n",
    "    '''\n",
    "    A helper fucntion that takes in a date and returns a value of 0 or 1 if the\n",
    "    date is during Chicago's Phase 3 Covid response (June 3-June 25, 2020).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    date : The date of a Divvy bike ride.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A 0 if the date did not take place during Phase 3 and a 1 if the ride took place during\n",
    "    Phase 3.\n",
    "    '''\n",
    "    if (date >= datetime.date(year=2020, month=6, day=3)) and (date <= datetime.date(year=2020, month=6, day=25)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def phase_four(date):\n",
    "    '''\n",
    "    A helper function that takes in a date and returns a value of 0 or 1 if the\n",
    "    date is during Chicago's Phase 4 Covid response (June 26-August 31, 2020).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    date : The date of a Divvy bike ride.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    False if the date did not take place during Phase 4 and True if the ride took place during\n",
    "    Phase 4.\n",
    "    '''\n",
    "    if (date >= datetime.date(year=2020, month=6, day=26)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T02:16:56.746556Z",
     "start_time": "2020-09-13T02:16:56.741850Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_covid_phase_dummys(all_data_2020):\n",
    "    '''\n",
    "    A function that takes adds Covid dummy variables to the 2020 bike share data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_data_2020 : The cleaned 2020 bike share data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dataframe with covid dummy variables.\n",
    "    '''\n",
    "    # Add in Covid dummy variable\n",
    "    all_data_2020['covid'] = all_data_2020.apply(lambda x: determine_covid(x['start_day_of_year']), axis=1)\n",
    "\n",
    "    # Add in phase dummy variables\n",
    "    all_data_2020['phase_one'] = all_data_2020.apply(lambda x: phase_one(x['start_day_of_year']), axis=1)\n",
    "    all_data_2020['phase_two'] = all_data_2020.apply(lambda x: phase_two(x['start_day_of_year']), axis=1)\n",
    "    all_data_2020['phase_three'] = all_data_2020.apply(lambda x: phase_three(x['start_day_of_year']), axis=1)\n",
    "    all_data_2020['phase_four'] = all_data_2020.apply(lambda x: phase_four(x['start_day_of_year']), axis=1)\n",
    "\n",
    "    return all_data_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T02:29:45.505574Z",
     "start_time": "2020-09-13T02:26:36.183847Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_2020 = add_covid_phase_dummys(all_data_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T02:29:45.598203Z",
     "start_time": "2020-09-13T02:29:45.590506Z"
    }
   },
   "outputs": [],
   "source": [
    "def phase_one_percent_change(all_data_2020, all_data_2019):\n",
    "    '''\n",
    "    A function that takes in 2 cleaned bike share dataframes and returns one\n",
    "    dataframe with percent change added to it from phase 1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_data_2020 : The cleaned 2020 bike share data.\n",
    "    all_data_2019 : The cleaned 2019 bike share data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dataframe with 2019 to 2020 phase 1 percent change column added.\n",
    "    '''\n",
    "    # 2020 Phase 1 Impact\n",
    "    phase_one_data = all_data_2020[all_data_2020['phase_one'] == 1]\n",
    "    phase_one_impact = phase_one_data.groupby(['from_station_id'], as_index=False).month.count()\n",
    "    phase_one_impact = phase_one_impact.rename(columns={'month': 'number_rides_2020'})\n",
    "    phase_one_impact = phase_one_impact.sort_values(by=['number_rides_2020'], ascending=False)\n",
    "\n",
    "    # 2019 Phase 1 Impact\n",
    "    phase_one_start_date = '03-17-2019'\n",
    "    phase_one_end_date = '04-30-2019'\n",
    "    phase_one_mask = (all_data_2019['start_time'] >= phase_one_start_date) & (all_data_2019['start_time'] <= phase_one_end_date)\n",
    "    pre_covid_data_phase_one = all_data_2019.loc[phase_one_mask]\n",
    "    pre_covid_impact_phase_one = pre_covid_data_phase_one.groupby(['from_station_id'], as_index=False).month.count()\n",
    "    pre_covid_impact_phase_one = pre_covid_impact_phase_one.rename(columns={'month': 'number_rides_2019'})\n",
    "    pre_covid_impact_phase_one = pre_covid_impact_phase_one.sort_values(by=['number_rides_2019'], ascending=False)\n",
    "\n",
    "    # Merge datasets together\n",
    "    phase_one_2019_and_2020 = pd.merge(phase_one_impact, pre_covid_impact_phase_one, on='from_station_id')\n",
    "    phase_one_2019_and_2020['phase_one_percent_change'] = (phase_one_2019_and_2020['number_rides_2020'] - phase_one_2019_and_2020['number_rides_2019'])/phase_one_2019_and_2020['number_rides_2019']\n",
    "    phase_one_2019_and_2020 = phase_one_2019_and_2020.sort_values(by=['phase_one_percent_change'], ascending=False)\n",
    "\n",
    "    # Rename columns to indicated number of rides from phase\n",
    "    phase_one_2019_and_2020 = phase_one_2019_and_2020.rename(columns={'number_rides_2020': 'phase_1_number_rides_2020', 'number_rides_2019': 'phase_1_number_rides_2019'})\n",
    "\n",
    "    return phase_one_2019_and_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T02:29:46.668990Z",
     "start_time": "2020-09-13T02:29:45.670672Z"
    }
   },
   "outputs": [],
   "source": [
    "phase_one_2019_and_2020 = phase_one_percent_change(all_data_2020, all_data_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_two_percent_change(all_data_2020, all_data_2019):\n",
    "    '''\n",
    "    A function that takes in 2 cleaned bike share dataframes and returns one\n",
    "    dataframe with percent change added to it from phase 2.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_data_2020 : The cleaned 2020 bike share data.\n",
    "    all_data_2019 : The cleaned 2019 bike share data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dataframe with 2019 to 2020 phase 2 percent change column added.\n",
    "    '''\n",
    "    # 2020 Phase 2 Impact\n",
    "    phase_two_data = all_data_2020[all_data_2020['phase_two'] == 1]\n",
    "    phase_two_impact = phase_two_data.groupby(['from_station_id'], as_index=False).month.count()\n",
    "    phase_two_impact = phase_two_impact.rename(columns={'month': 'number_rides_2020'})\n",
    "    phase_two_impact = phase_two_impact.sort_values(by=['number_rides_2020'], ascending=False)\n",
    "\n",
    "    # 2019 Phase 2 Impact\n",
    "    phase_two_start_date = '05-01-2019'\n",
    "    phase_two_end_date = '06-02-2019'\n",
    "    phase_two_mask = (all_data_2019['start_time'] >= phase_two_start_date) & (all_data_2019['start_time'] <= phase_two_end_date)\n",
    "    pre_covid_data_phase_two = all_data_2019.loc[phase_two_mask]\n",
    "    pre_covid_impact_phase_two = pre_covid_data_phase_two.groupby(['from_station_id'], as_index=False).month.count()\n",
    "    pre_covid_impact_phase_two = pre_covid_impact_phase_two.rename(columns={'month': 'number_rides_2019'})\n",
    "    pre_covid_impact_phase_two = pre_covid_impact_phase_two.sort_values(by=['number_rides_2019'], ascending=False)\n",
    "\n",
    "    # Merge datasets together\n",
    "    phase_two_2019_and_2020 = pd.merge(phase_two_impact, pre_covid_impact_phase_two, on='from_station_id')\n",
    "    phase_two_2019_and_2020['phase_two_percent_change'] = (phase_two_2019_and_2020['number_rides_2020'] - phase_two_2019_and_2020['number_rides_2019'])/phase_two_2019_and_2020['number_rides_2019']\n",
    "    phase_two_2019_and_2020 = phase_two_2019_and_2020.sort_values(by=['phase_two_percent_change'], ascending=False)\n",
    "\n",
    "    # Rename columns to indiciated number of rides from phase\n",
    "    phase_two_2019_and_2020 = phase_two_2019_and_2020.rename(columns={'number_rides_2020': 'phase_2_number_rides_2020', 'number_rides_2019': 'phase_2_number_rides_2019'})\n",
    "\n",
    "    return phase_two_2019_and_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_two_2019_and_2020 = phase_two_percent_change(all_data_2020, all_data_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_three_percent_change(all_data_2020, all_data_2019):\n",
    "    '''\n",
    "    A function that takes in 2 cleaned bike share dataframes and returns one\n",
    "    dataframe with percent change added to it from phase 3.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_data_2020 : The cleaned 2020 bike share data.\n",
    "    all_data_2019 : The cleaned 2019 bike share data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dataframe with 2019 to 2020 phase 3 percent change column added.\n",
    "    '''\n",
    "    # 2020 Phase 3 Impact\n",
    "    phase_three_data = all_data_2020[all_data_2020['phase_three'] == 1]\n",
    "    phase_three_impact = phase_three_data.groupby(['from_station_id'], as_index=False).month.count()\n",
    "    phase_three_impact = phase_three_impact.rename(columns={'month': 'number_rides_2020'})\n",
    "    phase_three_impact = phase_three_impact.sort_values(by=['number_rides_2020'], ascending=False)\n",
    "\n",
    "    # 2019 Phase 3 Impact\n",
    "    phase_three_start_date = '06-03-2019'\n",
    "    phase_three_end_date = '06-25-2019'\n",
    "    phase_three_mask = (all_data_2019['start_time'] >= phase_three_start_date) & (all_data_2019['start_time'] <= phase_three_end_date)\n",
    "    pre_covid_data_phase_three = all_data_2019.loc[phase_three_mask]\n",
    "    pre_covid_impact_phase_three = pre_covid_data_phase_three.groupby(['from_station_id'], as_index=False).month.count()\n",
    "    pre_covid_impact_phase_three = pre_covid_impact_phase_three.rename(columns={'month': 'number_rides_2019'})\n",
    "    pre_covid_impact_phase_three = pre_covid_impact_phase_three.sort_values(by=['number_rides_2019'], ascending=False)\n",
    "\n",
    "    # Merge datasets together\n",
    "    phase_three_2019_and_2020 = pd.merge(phase_three_impact, pre_covid_impact_phase_three, on='from_station_id')\n",
    "    phase_three_2019_and_2020['phase_three_percent_change'] = (phase_three_2019_and_2020['number_rides_2020'] - phase_three_2019_and_2020['number_rides_2019'])/phase_three_2019_and_2020['number_rides_2019']\n",
    "    phase_three_2019_and_2020 = phase_three_2019_and_2020.sort_values(by=['phase_three_percent_change'], ascending=False)\n",
    "\n",
    "    # Rename columns to indiciated number of rides from phase\n",
    "    phase_three_2019_and_2020 = phase_three_2019_and_2020.rename(columns={'number_rides_2020': 'phase_3_number_rides_2020', 'number_rides_2019': 'phase_3_number_rides_2019'})\n",
    "\n",
    "    return phase_three_2019_and_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_three_2019_and_2020 = phase_three_percent_change(all_data_2020, all_data_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_four_percent_change(all_data_2020, all_data_2019):\n",
    "    '''\n",
    "    A function that takes in 2 cleaned bike share dataframes and returns one\n",
    "    dataframe with percent change added to it from phase 4.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_data_2020 : The cleaned 2020 bike share data.\n",
    "    all_data_2019 : The cleaned 2019 bike share data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dataframe with 2019 to 2020 phase 4 percent change column added.\n",
    "    '''\n",
    "    # 2020 Phase 4 Impact\n",
    "    phase_four_data = all_data_2020[all_data_2020['phase_four'] == 1]\n",
    "    phase_four_impact = phase_four_data.groupby(['from_station_id'], as_index=False).month.count()\n",
    "    phase_four_impact = phase_four_impact.rename(columns={'month': 'number_rides_2020'})\n",
    "    phase_four_impact = phase_four_impact.sort_values(by=['number_rides_2020'], ascending=False)\n",
    "\n",
    "    # 2019 Phase 4 Impact\n",
    "    phase_four_start_date = '06-26-2019'\n",
    "    phase_four_end_date = '08-31-2019'\n",
    "    phase_four_mask = (all_data_2019['start_time'] >= phase_four_start_date) & (all_data_2019['start_time'] <= phase_four_end_date)\n",
    "    pre_covid_data_phase_four = all_data_2019.loc[phase_four_mask]\n",
    "    pre_covid_impact_phase_four = pre_covid_data_phase_four.groupby(['from_station_id'], as_index=False).month.count()\n",
    "    pre_covid_impact_phase_four = pre_covid_impact_phase_four.rename(columns={'month': 'number_rides_2019'})\n",
    "    pre_covid_impact_phase_four = pre_covid_impact_phase_four.sort_values(by=['number_rides_2019'], ascending=False)\n",
    "\n",
    "    # Merge datasets together\n",
    "    phase_four_2019_and_2020 = pd.merge(phase_four_impact, pre_covid_impact_phase_four, on='from_station_id')\n",
    "    phase_four_2019_and_2020['phase_four_percent_change'] = (phase_four_2019_and_2020['number_rides_2020'] - phase_four_2019_and_2020['number_rides_2019'])/phase_four_2019_and_2020['number_rides_2019']\n",
    "    phase_four_2019_and_2020 = phase_four_2019_and_2020.sort_values(by=['phase_four_percent_change'], ascending=False)\n",
    "\n",
    "    # Rename columns to indiciated number of rides from phase\n",
    "    phase_four_2019_and_2020 = phase_four_2019_and_2020.rename(columns={'number_rides_2020': 'phase_4_number_rides_2020', 'number_rides_2019': 'phase_4_number_rides_2019'})\n",
    "\n",
    "    return phase_four_2019_and_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_four_2019_and_2020 = phase_four_percent_change(all_data_2020, all_data_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divvy_data_with_lat_lng(phase_one_2019_and_2020, phase_two_2019_and_2020, phase_three_2019_and_2020, phase_four_2019_and_2020, divvy_bike_stations):\n",
    "    '''\n",
    "    A function that takes in each phase percent change dataframe and the divvy bike stations with latitude and\n",
    "    longitude information and returns one dataframe with everything merged together .\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    phase_one_2019_and_2020 : The phase one percent change dataframe.\n",
    "    phase_two_2019_and_2020 : The phase two percent change dataframe.\n",
    "    phase_three_2019_and_2020 : The phase three percent change dataframe.\n",
    "    phase_four_2019_and_2020 : The phase four percent change dataframe.\n",
    "    divvy_bike_stations : A dataframe with all 600+ Divvy stations and their latitude and longitude information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dataframe with all percent change data and station data merged together.\n",
    "    '''\n",
    "    phase_one_two = pd.merge(phase_one_2019_and_2020, phase_two_2019_and_2020, left_on='from_station_id', right_on='from_station_id')\n",
    "    phase_three_four = pd.merge(phase_three_2019_and_2020, phase_four_2019_and_2020, left_on='from_station_id', right_on='from_station_id')\n",
    "    all_data_percent_change_19_to_20 = pd.merge(phase_one_two, phase_three_four, left_on='from_station_id', right_on='from_station_id')\n",
    "\n",
    "    # Merge all_data_percent_change_19_to_20 with station latitude and longtiude data\n",
    "    all_data_with_lat_long = pd.merge(all_data_percent_change_19_to_20, divvy_bike_stations, left_on='from_station_id', right_on='ID')\n",
    "\n",
    "    return all_data_with_lat_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_lat_long = divvy_data_with_lat_lng(phase_one_2019_and_2020, phase_two_2019_and_2020, phase_three_2019_and_2020, phase_four_2019_and_2020, divvy_bike_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zip_codes_from_google_api(all_data_with_lat_long, your_api_key):\n",
    "    '''\n",
    "    A function that takes in the Divvy station data and an API and gets zip codes\n",
    "    for the Divvy stations using the Google Maps API.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_data_with_lat_long : All divvy data with latitude and longitude information.\n",
    "    your_api_key : Your API key to access Google Maps.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dataframe with zip codes for all Divvy stations.\n",
    "    '''\n",
    "    # Use Google Maps API to get zip code for each Divvy station\n",
    "    geolocator = GoogleV3(api_key=your_api_key)\n",
    "\n",
    "    zip_codes = []\n",
    "\n",
    "    latitudes = addresses['Latitude']\n",
    "    longitudes = addresses['Longitude']\n",
    "\n",
    "    for lat, lng in zip(latitudes, longitudes):\n",
    "        location = geolocator.reverse(str(lat) + ', ' + str(lng))\n",
    "        cleaned_zip = int(location[0].split()[-2][:-1])\n",
    "        zip_codes.append(cleaned_zip)\n",
    "\n",
    "    # Convert zip code list into an array and add to dataframe\n",
    "    zip_code_array = np.asarray(zip_codes)\n",
    "    all_data_with_lat_long['zip_code'] = zip_code_array\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    zip_code_location_divvy_stations = all_data_with_lat_long.drop([\n",
    "       'from_station_id',\n",
    "       'phase_1_number_rides_2020', 'Longitude', 'Latitude',\n",
    "       'phase_1_number_rides_2019', 'phase_one_percent_change',\n",
    "       'phase_2_number_rides_2020', 'phase_2_number_rides_2019',\n",
    "       'phase_two_percent_change', 'phase_3_number_rides_2020',\n",
    "       'phase_3_number_rides_2019', 'phase_three_percent_change',\n",
    "       'phase_4_number_rides_2020', 'phase_4_number_rides_2019',\n",
    "       'phase_four_percent_change', 'ID', 'Station Name', 'Total Docks',\n",
    "       'Docks in Service', 'Status'], axis=1)\n",
    "\n",
    "    return zip_code_location_divvy_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The previous script was ran before, so just loading it in below\n",
    "zip_code_location_divvy_stations = pd.read_csv('../Data/zip_code_location_divvy_stations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_for_tableau(zip_code_location_divvy_stations, all_data_with_lat_long, chicago_zip_pop_data):\n",
    "    '''\n",
    "    A function that takes in the Divvy station data and an API and gets zip codes\n",
    "    for the Divvy stations using the Google Maps API.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    zip_code_location_divvy_stations : A dataframe with the zip code for every Divvy station\n",
    "    all_data_with_lat_long : All divvy data with latitude and longitude information.\n",
    "    chicago_zip_pop_data : A dataframe with total population by Chicago zip code.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A saved csv with all data needed to create tableau visualizations\n",
    "    '''\n",
    "    # Merge zip codes and all Divvy data\n",
    "    all_divvy_with_zips = pd.merge(all_data_with_lat_long, chicago_zip_pop_data, left_on='Location', right_on='Location')\n",
    "\n",
    "    # Convert zipcode column in chicago_zip_pop_data to integer type\n",
    "    chicago_zip_pop_data['Geography'] = chicago_zip_pop_data.Geography.astype('int')\n",
    "\n",
    "    # Merge chicago_zip_pop_data with all_divvy_with_zips\n",
    "    all_data = pd.merge(all_divvy_with_zips, chicago_zip_pop_data, left_on ='zip_code', right_on='Geography', how='outer')\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    all_data = all_data.drop(['Population - Age 0-17', 'Population - Age 18-29', 'Year', 'Geography Type', 'Status',\n",
    "       'Population - Age 30-39', 'Population - Age 40-49', 'Location', 'Total Docks', 'Docks in Service',\n",
    "       'Population - Age 50-59', 'Population - Age 60-69', 'Record ID', 'zip_code', 'ID', 'Population - Latinx',\n",
    "       'Population - Age 70-79', 'Population - Age 80+', 'Population - Female', 'Population - Male',\n",
    "       'Population - Asian Non-Latinx', 'Population - Black Non-Latinx', 'Population - White Non-Latinx',\n",
    "       'Population - Other Race Non-Latinx'], axis = 1)\n",
    "\n",
    "    # Add percent change column multiplied by 100\n",
    "    all_data['phase_one_percent_change_as_percent'] = all_data['phase_one_percent_change'] * 100\n",
    "    all_data['phase_two_percent_change_as_percent'] = all_data['phase_two_percent_change'] * 100\n",
    "    all_data['phase_three_percent_change_as_percent'] = all_data['phase_three_percent_change'] * 100\n",
    "    all_data['phase_four_percent_change_as_percent'] = all_data['phase_four_percent_change'] * 100\n",
    "\n",
    "    # Rename columns\n",
    "    all_data.rename(columns={'from_station_id':'divvy_station_id', 'Geography': 'zip_code'})\n",
    "\n",
    "    # Drop percent change as decimal columns\n",
    "    all_data = all_data.drop(['phase_one_percent_change', 'phase_two_percent_change', 'phase_three_percent_change', 'phase_four_percent_change'], axis = 1)\n",
    "\n",
    "    # Save file as csv to upload into Tableau\n",
    "    save_to_csv(all_data, 'all_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_for_tableau(zip_code_location_divvy_stations, all_data_with_lat_long, chicago_zip_pop_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
